<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Body Tracking</title>
    <!-- Tailwind CSS for styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Google Fonts for a clean look -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #000; /* Black background for the page */
        }
        /* Make the container fill the entire screen, fixed in the background */
        .stack-container {
            position: fixed;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            z-index: 1;
            perspective: 1000px; /* Add perspective for 3D transforms */
        }
        /* Make video and canvas fill the container, covering the area without distortion */
        .stack-container > * {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        #output_canvas {
            transform-origin: 0 0; /* Set transform origin for predictable transformations */
            border: 2px solid red; /* Add a red border to show the canvas limits */
        }
        #webcam {
            display: none;
        }
        /* UI Overlay container */
        .ui-overlay {
            position: fixed;
            inset: 0; /* top, right, bottom, left = 0 */
            z-index: 10;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 2rem;
            pointer-events: none; /* Allows clicks to 'go through' the container */
        }
        /* Re-enable pointer events for elements inside the overlay */
        .ui-overlay > * {
            pointer-events: auto;
        }
        /* Container to push buttons to the bottom */
        .controls-container {
            margin-top: auto;
            text-align: center;
        }
        /* Styles for the perspective controls */
        #perspective-controls {
            position: absolute;
            top: 1rem;
            left: 1rem;
            background-color: rgba(0, 0, 0, 0.6);
            padding: 1rem;
            border-radius: 0.5rem;
            display: none; /* Hidden by default */
            font-size: 0.8rem;
            width: 250px;
        }
        #perspective-controls label {
            display: block;
            margin-bottom: 0.25rem;
        }
        #perspective-controls input[type="range"] {
            width: 100%;
            margin-bottom: 0.5rem;
        }
    </style>
</head>
<body class="bg-black text-white">

    <!-- Container for the video feed and canvas, now in the background -->
    <div id="liveView" class="stack-container">
        <video id="webcam" autoplay playsinline></video>
        <canvas id="output_canvas"></canvas>
    </div>

    <!-- UI Elements that overlay the video feed -->
    <div class="ui-overlay">

        <div id="perspective-controls">
            <h4 class="font-bold mb-2">Perspective Controls</h4>
            <div>
                <label for="tlx">Top Left X</label>
                <input type="range" id="tlx" min="0" max="100" value="15">
                <label for="tly">Top Left Y</label>
                <input type="range" id="tly" min="0" max="100" value="20">
            </div>
            <div class="mt-2">
                <label for="trx">Top Right X</label>
                <input type="range" id="trx" min="0" max="100" value="85">
                <label for="try">Top Right Y</label>
                <input type="range" id="try" min="0" max="100" value="20">
            </div>
             <div class="mt-2">
                <label for="brx">Bottom Right X</label>
                <input type="range" id="brx" min="0" max="100" value="95">
                <label for="bry">Bottom Right Y</label>
                <input type="range" id="bry" min="0" max="100" value="90">
            </div>
             <div class="mt-2">
                <label for="blx">Bottom Left X</label>
                <input type="range" id="blx" min="0" max="100" value="5">
                <label for="bly">Bottom Left Y</label>
                <input type="range" id="bly" min="0" max="100" value="90">
            </div>
        </div>

        <div class="controls-container">
            <div class="flex items-center justify-center gap-4">
                 <button id="webcamButton" class="bg-gradient-to-r from-purple-500 to-pink-500 hover:from-purple-600 hover:to-pink-600 text-white font-semibold py-3 px-8 rounded-full shadow-lg transform hover:scale-105 transition-transform duration-300 ease-in-out disabled:opacity-50 disabled:cursor-not-allowed">
                    Enable Webcam
                </button>
                <button id="toggleBgButton" class="bg-gray-700 hover:bg-gray-600 text-white font-semibold py-3 px-8 rounded-full shadow-lg transform hover:scale-105 transition-transform duration-300 ease-in-out" style="display: none;">
                    Show Webcam
                </button>
            </div>
             <div id="loading" class="text-gray-400 mt-4" style="display: none;">
                <svg class="animate-spin h-5 w-5 mr-3 inline-block" viewBox="0 0 24 24">
                    <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                    <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                </svg>
                Loading AI Model...
            </div>
        </div>
    </div>

    <!-- MediaPipe Vision Tasks -->
    <script type="module">
        import {
            PoseLandmarker,
            FilesetResolver,
            DrawingUtils
        } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

        // Get DOM elements
        const video = document.getElementById("webcam");
        const canvasElement = document.getElementById("output_canvas");
        const canvasCtx = canvasElement.getContext("2d");
        const webcamButton = document.getElementById("webcamButton");
        const loadingElement = document.getElementById("loading");
        const liveView = document.getElementById("liveView");
        const toggleBgButton = document.getElementById("toggleBgButton");
        const perspectiveControls = document.getElementById("perspective-controls");

        let poseLandmarker = undefined;
        let runningMode = "VIDEO";
        let webcamRunning = false;
        let drawingUtils;
        let lastVideoTime = -1;
        let smoothedLandmarks; // Variable to store the smoothed landmark data
        let isWebcamBackground = false; // State for background toggle

        // --- 1. INITIALIZE THE MODEL ---
        const createPoseLandmarker = async () => {
            const vision = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
            );
            poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
                baseOptions: {
                    // Use a lighter model for better performance on the web
                    modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,
                    delegate: "GPU"
                },
                runningMode: runningMode,
                numPoses: 1 // Track a single person for this demo
            });
            drawingUtils = new DrawingUtils(canvasCtx);
            
            // Hide loading and enable the button once the model is ready
            loadingElement.style.display = 'none';
            webcamButton.disabled = false;
            console.log("PoseLandmarker model loaded.");
        };

        // Show loading and start creating the model
        webcamButton.disabled = true;
        loadingElement.style.display = 'block';
        createPoseLandmarker();

        // --- 2. ENABLE WEBCAM AND START PREDICTIONS ---
        const enableCam = (event) => {
            if (!poseLandmarker) {
                console.log("Wait! poseLandmarker not loaded yet.");
                return;
            }

            if (webcamRunning) {
                webcamRunning = false;
                webcamButton.innerText = "Enable Webcam";
                video.pause();
                video.srcObject.getTracks().forEach(track => track.stop());
                video.srcObject = null;
                canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
                smoothedLandmarks = undefined; // Reset smoothing on disable
                toggleBgButton.style.display = 'none'; // Hide the toggle button
                perspectiveControls.style.display = 'none'; // Hide controls
                video.style.display = 'none'; // Hide video element
                isWebcamBackground = false; // Reset background state
            } else {
                webcamRunning = true;
                webcamButton.innerText = "Disable Webcam";
                toggleBgButton.style.display = 'inline-block'; // Show the toggle button
                perspectiveControls.style.display = 'block'; // Show controls
                toggleBgButton.innerText = 'Show Webcam'; // Reset button text

                // Activate the webcam stream
                navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
                    video.srcObject = stream;
                    // When the video data is loaded, set canvas dimensions and start the loop
                    video.addEventListener("loadeddata", startPredictionLoop);
                }).catch((err) => {
                    console.error("Error accessing webcam: ", err);
                    webcamRunning = false;
                    webcamButton.innerText = "Enable Webcam";
                });
            }
        };

        webcamButton.addEventListener("click", enableCam);

        toggleBgButton.addEventListener("click", () => {
            isWebcamBackground = !isWebcamBackground;
            if (isWebcamBackground) {
                video.style.display = 'block';
                toggleBgButton.innerText = 'Hide Webcam';
            } else {
                video.style.display = 'none';
                toggleBgButton.innerText = 'Show Webcam';
            }
        });
        
        // --- 3. PREDICTION LOOP ---
        const startPredictionLoop = () => {
            // Set canvas size to match video feed ONCE
            canvasElement.width = video.videoWidth;
            canvasElement.height = video.videoHeight;
            
            // Calculate and apply the perspective transform
            applyPerspectiveTransform();

            // Start the continuous prediction loop
            predictWebcam();
        }

        const predictWebcam = async () => {
            // This check prevents the model from processing a frame before the video is ready,
            // which is the cause of the "ROI width and height must be > 0" error.
            if (video.videoWidth === 0 || video.videoHeight === 0) {
                if (webcamRunning) {
                    window.requestAnimationFrame(predictWebcam);
                }
                return; // Skip this frame if dimensions are not available yet.
            }

            // Smoothing factor - lower value means more smoothing but more latency
            const smoothingFactor = 0.25;

            let startTimeMs = performance.now();
            if (lastVideoTime !== video.currentTime) {
                lastVideoTime = video.currentTime;
                poseLandmarker.detectForVideo(video, startTimeMs, (result) => {
                    canvasCtx.save();
                    
                    // Clear canvas. If webcam is visible, this makes it transparent.
                    canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
                    
                    // If webcam background is off, draw a black background.
                    if (!isWebcamBackground) {
                        canvasCtx.fillStyle = "black";
                        canvasCtx.fillRect(0, 0, canvasElement.width, canvasElement.height);
                    }

                    // --- Smoothing Logic ---
                    if (result.landmarks && result.landmarks.length > 0) {
                        const newLandmarks = result.landmarks[0];

                        if (!smoothedLandmarks) {
                            // If it's the first detection, initialize with a deep copy of the landmarks
                            smoothedLandmarks = JSON.parse(JSON.stringify(newLandmarks));
                        } else {
                            // Apply Exponential Moving Average to each landmark
                            for (let i = 0; i < newLandmarks.length; i++) {
                                smoothedLandmarks[i].x = smoothingFactor * newLandmarks[i].x + (1 - smoothingFactor) * smoothedLandmarks[i].x;
                                smoothedLandmarks[i].y = smoothingFactor * newLandmarks[i].y + (1 - smoothingFactor) * smoothedLandmarks[i].y;
                                smoothedLandmarks[i].z = smoothingFactor * newLandmarks[i].z + (1 - smoothingFactor) * smoothedLandmarks[i].z;
                                // We can just take the latest visibility value
                                smoothedLandmarks[i].visibility = newLandmarks[i].visibility;
                            }
                        }

                        // Draw the SMOOTHED landmarks and connections
                        drawingUtils.drawLandmarks(smoothedLandmarks, {
                            radius: (data) => DrawingUtils.lerp(data.from.z, -0.15, 0.1, 5, 1),
                            color: '#FFFFFF' // white dots
                        });
                        drawingUtils.drawConnectors(smoothedLandmarks, PoseLandmarker.POSE_CONNECTIONS, {
                            color: (data) => {
                                // Gradient color for connections
                                // const t = (data.from.z + data.to.z) / 2 + 0.5;
                                // const r = Math.floor(255 * (1 - t) + 171 * t); // from FF to AB (pink to purple)
                                // const g = Math.floor(0 * (1 - t) + 71 * t);
                                // const b = Math.floor(255 * (1 - t) + 188 * t);
                                // return `rgb(${r},${g},${b})`;
                                return `rgb(120,0,0)`;
                            },
                             lineWidth: 8
                        });
                    }
                    canvasCtx.restore();
                });
            }

            // Call this function again to keep predicting when the browser is ready
            if (webcamRunning) {
                window.requestAnimationFrame(predictWebcam);
            }
        };

        // --- 4. PERSPECTIVE TRANSFORM LOGIC ---

        const applyPerspectiveTransform = () => {
             if (!webcamRunning) return;
            // Define the destination points for the perspective transform based on the container size
            const w = liveView.clientWidth;
            const h = liveView.clientHeight;
            
            // Source points are the corners of the element's bounding box
            const srcPts = [ { x: 0, y: 0 }, { x: w, y: 0 }, { x: w, y: h }, { x: 0, y: h } ];

            // Destination points are now read dynamically from the sliders
            const dstPts = [
                { x: w * (parseInt(document.getElementById('tlx').value) / 100), y: h * (parseInt(document.getElementById('tly').value) / 100) },
                { x: w * (parseInt(document.getElementById('trx').value) / 100), y: h * (parseInt(document.getElementById('try').value) / 100) },
                { x: w * (parseInt(document.getElementById('brx').value) / 100), y: h * (parseInt(document.getElementById('bry').value) / 100) },
                { x: w * (parseInt(document.getElementById('blx').value) / 100), y: h * (parseInt(document.getElementById('bly').value) / 100) }
            ];

            // Calculate and apply the transform matrix as a CSS style
            const transformMatrix = getTransform(srcPts, dstPts);
            canvasElement.style.transform = transformMatrix;
        }
        
        // Recalculate the transform on window resize to keep it responsive
        window.addEventListener('resize', applyPerspectiveTransform);

        // Add event listeners to all sliders to update the transform on change
        document.querySelectorAll('#perspective-controls input[type="range"]').forEach(slider => {
            slider.addEventListener('input', applyPerspectiveTransform);
        });

        /**
         * Calculates the 3D transformation matrix needed to map 4 source points to 4 destination points.
         * @param {Array<{x: number, y: number}>} srcPts - The source corner points.
         * @param {Array<{x: number, y: number}>} dstPts - The destination corner points.
         * @returns {string} A CSS matrix3d() transform string.
         */
        function getTransform(srcPts, dstPts) {
            const A = new Array(8).fill(0).map(() => new Array(8).fill(0));
            const b = new Array(8);

            for (let i = 0; i < 4; i++) {
                const sp = srcPts[i];
                const dp = dstPts[i];
                A[i*2][0] = A[i*2+1][3] = sp.x;
                A[i*2][1] = A[i*2+1][4] = sp.y;
                A[i*2][2] = A[i*2+1][5] = 1;
                A[i*2][6] = -sp.x * dp.x;
                A[i*2][7] = -sp.y * dp.x;
                A[i*2+1][6] = -sp.x * dp.y;
                A[i*2+1][7] = -sp.y * dp.y;

                b[i*2] = dp.x;
                b[i*2+1] = dp.y;
            }

            const h = gaussianElimination(A, b);

            const matrix = [
                h[0], h[3], 0, h[6],
                h[1], h[4], 0, h[7],
                0   , 0   , 1, 0,
                h[2], h[5], 0, 1
            ];
            
            return `matrix3d(${matrix.join(',')})`;
        }

        /**
         * Solves a system of linear equations Ax=b using Gaussian elimination.
         * @param {Array<Array<number>>} A - The matrix A.
         * @param {Array<number>} b - The vector b.
         * @returns {Array<number>} The solution vector x.
         */
        function gaussianElimination(A, b) {
            const n = A.length;
            for (let i = 0; i < n; i++) {
                let maxRow = i;
                for (let k = i + 1; k < n; k++) {
                    if (Math.abs(A[k][i]) > Math.abs(A[maxRow][i])) {
                        maxRow = k;
                    }
                }
                [A[i], A[maxRow]] = [A[maxRow], A[i]];
                [b[i], b[maxRow]] = [b[maxRow], b[i]];

                for (let k = i + 1; k < n; k++) {
                    const factor = A[k][i] / A[i][i];
                    if (isFinite(factor)) {
                         for (let j = i; j < n; j++) {
                            A[k][j] -= factor * A[i][j];
                        }
                        b[k] -= factor * b[i];
                    }
                }
            }

            const x = new Array(n);
            for (let i = n - 1; i >= 0; i--) {
                let sum = 0;
                for (let j = i + 1; j < n; j++) {
                    sum += A[i][j] * x[j];
                }
                x[i] = (b[i] - sum) / A[i][i];
            }
            return x.map(val => isFinite(val) ? val : 0);
        }
    </script>
</body>
</html>

